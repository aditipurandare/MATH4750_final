{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize Data into CSV and Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee70811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Census Sales Data\n",
    "\n",
    "df_nonadjust = pd.DataFrame()\n",
    "df_label = pd.DataFrame()\n",
    "xlfname = 'mrtssales92-present (1).xlsx'\n",
    "xl = pd.ExcelFile(xlfname)\n",
    "\n",
    "### Labels\n",
    "df_label = xl.parse(xl.sheet_names[0], header=4, usecols='A:B',nrows = 66)\n",
    "df_label = df_label.drop([0,1,2,3,4,5,6,7])\n",
    "df_label = df_label.set_axis([\"NAICS Code\",\"Business Type\"],axis=1)\n",
    "\n",
    "### Not adjusted\n",
    "for sheet in xl.sheet_names:\n",
    "    df_tmp = pd.DataFrame()\n",
    "    if sheet == '2023':\n",
    "        df_tmp = xl.parse(sheet, header=4, usecols='C:K',nrows = 66)\n",
    "    else:\n",
    "        df_tmp = xl.parse(sheet, header=4,usecols='C:N',nrows = 66)\n",
    "    df_tmp = df_tmp.drop([0,1,2,3,4,5,6,7])\n",
    "    df_nonadjust = pd.concat([df_nonadjust,df_tmp], axis = 1, ignore_index=False,sort=False)\n",
    "\n",
    "df_nonadjust = pd.concat([df_label,df_nonadjust], axis = 1, ignore_index=False,sort=False)\n",
    "\n",
    "\n",
    "csvfile = 'CensusNonAdjusted.csv'\n",
    "df_nonadjust.to_csv(csvfile, index=False)\n",
    "\n",
    "\n",
    "# Need to organize this further and then get matrix with specific columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zillow Housing Price Data\n",
    "\n",
    "df = pd.read_csv('State_time_series.csv',parse_dates=['Date'])\n",
    "data = pd.DataFrame(zip(df.Date, df.Sale_Prices, df.ZHVI_AllHomes),\n",
    "               columns =['Date', 'Sale_Prices','ZHVI'])\n",
    "data1_drop = data.dropna(thresh=3)\n",
    "data1_drop.reset_index(drop = True)\n",
    "\n",
    "csvfile = 'Zillow.csv'\n",
    "data1_drop.to_csv(csvfile, index=False)\n",
    "\n",
    "Zillow_Data = data1_drop # specific columns to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hotel Booking Data\n",
    "\n",
    "df = pd.read_csv('hotel_bookings_raw.csv',parse_dates=['reservation_status_date'])\n",
    "data = pd.DataFrame(zip(df.reservation_status_date, df.stays_in_weekend_nights, df.stays_in_week_nights, df.INFLATION, df.GDP, df.FUEL_PRCS),\n",
    "               columns =['Date', 'Weekend Nights','Week Nights', 'Inflation', 'GDP', \"Fuel Prices\"])\n",
    "data1_drop = data.dropna()\n",
    "data1_drop.reset_index(drop = True)\n",
    "\n",
    "csvfile = 'Hotel.csv'\n",
    "data1_drop.to_csv(csvfile, index=False)\n",
    "\n",
    "Hotel_Data = data1_drop # specific columns to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coffee Sales Data\n",
    "\n",
    "df = pd.read_csv('Coffee_domestic_consumption.csv')\n",
    "data1_drop = df.dropna()\n",
    "data1_drop.reset_index(drop = True)\n",
    "\n",
    "csvfile = 'Coffee.csv'\n",
    "data1_drop.to_csv(csvfile, index=False)\n",
    "\n",
    "Coffee_Data = data1_drop # specific columns to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Avocado Sales Data\n",
    "\n",
    "df = pd.read_csv('avocado_sheet.csv')\n",
    "data = pd.DataFrame(zip(df.AveragePrice, df.Total_Volume, df.Total_Bags, df.year, df.region),\n",
    "               columns =['Price', 'Volume','Bags','Year',\"Region\"])\n",
    "data1_drop = data.dropna()\n",
    "data1_drop.reset_index(drop = True)\n",
    "\n",
    "csvfile = 'Avocado.csv'\n",
    "data1_drop.to_csv(csvfile, index=False)\n",
    "\n",
    "Avocado_Data = data1_drop # specific columns to use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd80782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit function to normalize array\n",
    "def normalize(arr, t_min, t_max):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = max(arr) - min(arr)    \n",
    "    for i in arr:\n",
    "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr\n",
    "\n",
    "# What to normalize?\n",
    "# Will need to organize data better, all are different "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Regression/Correlation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for different methods\n",
    "def LinearReg(x,y):  # Code for regression using the Normal Equation (X.T*X)*theta = (X.T*y)\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x])  # Concatenate x with a column of ones on the left\n",
    "    theta=(np.linalg.solve(np.matmul(X.T,X),np.matmul(X.T,y)))\n",
    "    return theta\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def grad_linear(theta,x,y): # Gradient for linear regression\n",
    "    z= x.dot(theta)\n",
    "    gradient = (1/len(x))*np.matmul(x.T,z-y)\n",
    "    return gradient\n",
    "\n",
    "def grad_linear_stoch (theta,x,y): # Gradient for stochastic linear regression\n",
    "    z=x.dot(theta)\n",
    "    gradient = (1/len(x))*x*(z-y)\n",
    "    return gradient\n",
    "\n",
    "def grad_logistic(theta,x,y): # Gradient for logistic regression\n",
    "    z=x.dot(theta)\n",
    "    gradient = (1/len(x))*np.matmul(x.T,sigmoid(z)-y)\n",
    "    return gradient\n",
    "\n",
    "def GradientDescent(x,y,theta,alpha,iteration,grad): # Code for gradient descent\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x]) # Concatenate x with a column of ones on the left\n",
    "    theta_list = [theta]\n",
    "    for i in range(iteration):\n",
    "        theta = theta - alpha*grad(theta,X,y)\n",
    "        theta_list.append(theta)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    return theta, h, theta_list\n",
    "\n",
    "def StochasticGD(x,y,theta,alpha,iteration,grad): # Code for stochastic gradient descent\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x]) # Concatenate x with a column of ones on the left\n",
    "    theta_list = [theta]\n",
    "    for i in range(iteration):\n",
    "        k=random.randint(1,x.shape[0]-1)\n",
    "        theta = theta - alpha*grad(theta,X[k],y[k])\n",
    "        theta_list.append(theta)\n",
    "    return theta, theta_list\n",
    "\n",
    "def newton_method(x, y, num_iterations):\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x])  # Concatenate x with a column of ones on the left\n",
    "    m, n = X.shape  \n",
    "    theta = np.zeros(n)  # Initialize the parameters\n",
    "    for _ in range(num_iterations):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        gradient = np.dot(X.T,(h-y))/m  # Calculate the gradient and Hessian\n",
    "        diagonal = np.diag(h*(1-h))\n",
    "        hessian = (1/m)*np.dot(X.T, np.dot(diagonal,X))\n",
    "        theta = theta - np.dot(np.linalg.inv(hessian), gradient) # Update theta using Newton's method\n",
    "    return theta, sigmoid(np.dot(X, theta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
