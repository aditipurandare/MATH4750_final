{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize Data into CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee70811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n",
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3907989305.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_quarter[label]=quarters[:,i]\n"
     ]
    }
   ],
   "source": [
    "### Census Sales Data\n",
    "\n",
    "df_nonadjust = pd.DataFrame()\n",
    "df_label = pd.DataFrame()\n",
    "xlfname = 'mrtssales92-present (1).xlsx'\n",
    "xl = pd.ExcelFile(xlfname)\n",
    "\n",
    "### Labels\n",
    "df_label = xl.parse(xl.sheet_names[0], header=4, usecols='A:B',nrows = 66)\n",
    "df_label = df_label.drop([0,1,2,3,4,5,6,7])\n",
    "df_label = df_label.set_axis([\"NAICS Code\",\"Business Type\"],axis=1)\n",
    "\n",
    "### Not adjusted\n",
    "for sheet in reversed(xl.sheet_names):\n",
    "    df_tmp = pd.DataFrame()\n",
    "    if sheet == '2023':\n",
    "        df_tmp = xl.parse(sheet, header=4, usecols='C:K',nrows = 66)\n",
    "    else:\n",
    "        df_tmp = xl.parse(sheet, header=4,usecols='C:N',nrows = 66)\n",
    "    df_tmp = df_tmp.drop([0,1,2,3,4,5,6,7])\n",
    "    df_nonadjust = pd.concat([df_nonadjust,df_tmp], axis = 1, ignore_index=False,sort=False)\n",
    "\n",
    "# get quartly sums for each business type\n",
    "\n",
    "quarters = []\n",
    "for i in range(len(df_nonadjust)):\n",
    "    row = []\n",
    "    temp_sum = 0\n",
    "    m = 1\n",
    "    for j in range(len(df_nonadjust.columns)):\n",
    "        if df_nonadjust.iat[i,j] != '(S)' and df_nonadjust.iat[i,j] != '(NA)' :\n",
    "            temp_sum+=int(df_nonadjust.iat[i,j])\n",
    "        if (m % 3 == 0) or (j == len(df_nonadjust.columns)-1):\n",
    "            row.append(temp_sum)\n",
    "            temp_sum = 0\n",
    "            m = 1\n",
    "        else:\n",
    "            m+=1\n",
    "    quarters.append(row)\n",
    "\n",
    "df_quarter = df_label\n",
    "year = 1992\n",
    "quarters = np.array(quarters)\n",
    "for i in range(len(quarters[0])):\n",
    "    q = (i+1) % 4\n",
    "    label = ''\n",
    "    if q == 0:\n",
    "        label = 'Q'+str(4)+' '+str(year)\n",
    "        year+=1\n",
    "    else:\n",
    "        label = 'Q'+str(q)+' '+str(year)\n",
    "    df_quarter[label]=quarters[:,i]\n",
    "\n",
    "Census_data = df_quarter.copy()\n",
    "\n",
    "csvfile = 'CensusNonAdjusted.csv'\n",
    "df_quarter.to_csv(csvfile, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GDP \n",
    "\n",
    "df = pd.read_csv('GDP raw.csv',parse_dates=['DATE'])\n",
    "\n",
    "quarters = []\n",
    "for d in df.DATE:\n",
    "    q = (int(d.month)-1)/3+1\n",
    "    label = \"Q\"+str(int(q))+\" \"+ str(d.year)\n",
    "    quarters.append(label)\n",
    "\n",
    "df['Quarter'] = quarters\n",
    "\n",
    "csvfile = 'GDP.csv'\n",
    "df.to_csv(csvfile, index=False)\n",
    "\n",
    "GDP_Data = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zillow Housing Price Data\n",
    "\n",
    "df = pd.read_csv('Zillow_Raw.csv',parse_dates=['DATE'])\n",
    "data = pd.DataFrame(zip(df.DATE, df.ZHVI),\n",
    "               columns =['Date','ZHVI'])\n",
    "\n",
    "\n",
    "quarters = []\n",
    "labels = []\n",
    "m = 1\n",
    "q = 1\n",
    "temp_sum = 0\n",
    "for i in range(len(data.Date)):\n",
    "    temp_sum+=int(data.ZHVI.iat[i])\n",
    "    if (m % 3 == 0) or (i == len(data.Date)-1):\n",
    "        quarters.append(temp_sum/3.0)\n",
    "        labels.append('Q'+str(q)+' '+str(data.Date.iat[i].year))\n",
    "        temp_sum = 0\n",
    "        m = 1\n",
    "        q+=1\n",
    "    else:\n",
    "        m+=1\n",
    "\n",
    "    if q == 5:\n",
    "        q = 1\n",
    "\n",
    "\n",
    "new_data = pd.DataFrame()\n",
    "new_data['Quarter'] = labels\n",
    "new_data['ZHVI'] = quarters\n",
    "\n",
    "csvfile = 'Zillow.csv'\n",
    "new_data.to_csv(csvfile, index=False)\n",
    "\n",
    "Zillow_Data = new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coffee Production Data\n",
    "\n",
    "df = pd.read_csv('Coffee_production.csv', parse_dates=['DATE'])\n",
    "\n",
    "quarters = []\n",
    "for d in df.DATE:\n",
    "    q = (int(d.month)-1)/3+1\n",
    "    label = \"Q\"+str(int(q))+\" \"+ str(d.year)\n",
    "    quarters.append(label)\n",
    "\n",
    "df['Quarter'] = quarters\n",
    "df = df.set_axis([\"Date\",\"PI\",\"Quarter\"],axis=1)\n",
    "\n",
    "csvfile = 'Coffee.csv'\n",
    "df.to_csv(csvfile, index=False) \n",
    "\n",
    "Coffee_Data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9fd80782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_42252\\3018682004.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  census_names.append(row[1])\n"
     ]
    }
   ],
   "source": [
    "# explicit function to normalize array\n",
    "def normalize(arr, t_min, t_max):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = max(arr) - min(arr)    \n",
    "    for i in arr:\n",
    "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr\n",
    "\n",
    "def quarter_to_num(columns):\n",
    "    tmp = []\n",
    "    for i in range(len(columns)):\n",
    "        q_y = [int(columns[i][1]),int(columns[i][3:])]\n",
    "        tmp.append(q_y)\n",
    "    return np.array(tmp)\n",
    "    \n",
    "\n",
    "Census_data = df_quarter.copy()\n",
    "c = len(Census_data.columns)\n",
    "r = len(Census_data)\n",
    "\n",
    "census_y = []\n",
    "census_names = []\n",
    "census_x = quarter_to_num(Census_data.columns[2:])\n",
    "# Census\n",
    "for i in range(r):\n",
    "    row = Census_data.iloc[i]\n",
    "    n_row = normalize(row[2:], 0 , 1)\n",
    "    census_y.append(n_row)\n",
    "    census_names.append(row[1])\n",
    "    for j in range(2,c):\n",
    "        Census_data.at[i,Census_data.columns[j]] = n_row[j-2]\n",
    "census_y = np.array(census_y)\n",
    "\n",
    "# GDP\n",
    "GDP_Data.GDPC1 = normalize(GDP_Data.GDPC1, 0 , 1)\n",
    "GDP_x = quarter_to_num(GDP_Data.Quarter)\n",
    "GDP_y = GDP_Data.GDPC1\n",
    "\n",
    "# Zillow\n",
    "Zillow_Data.ZHVI = normalize(Zillow_Data.ZHVI, 0 , 1)\n",
    "Zillow_x = quarter_to_num(Zillow_Data.Quarter)\n",
    "Zillow_y = Zillow_Data.ZHVI\n",
    "\n",
    "# Coffee\n",
    "Coffee_Data.PI = normalize(Coffee_Data.PI, 0 , 1)\n",
    "Coffee_x = quarter_to_num(Coffee_Data.Quarter)\n",
    "Coffee_y = Coffee_data.PI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get x an y for each to be used in regression\n",
    "\n",
    "# Census\n",
    "# census_y consists of rows of all the sales for different categories\n",
    "# census_names consists of all the names of categories, same indices as their corresponding values \n",
    "# census_x contains a list of years and corresponding quarters\n",
    "census_x_interval = census_x[:,1]+census_x[:,0]/4.0 # this contains years plus quarter/4 to create incremented x values\n",
    "\n",
    "# GDP\n",
    "# GDP_y consists of all GDP values\n",
    "# GDP_x consists of a list of years and corresponding quarters\n",
    "GDP_x_interval = GDP_x[:,1]+GDP_x[:,0]/4.0\n",
    "\n",
    "# Zillow\n",
    "# Zillow_y consists of all house index values\n",
    "# Zillow_x consists of a list of years and corresponding quarters\n",
    "Zillow_x_interval = Zillow_x[:,1]+Zillow_x[:,0]/4.0\n",
    "\n",
    "# Coffee\n",
    "# Coffee_y consists of all producer indexes \n",
    "# Coffee_x consists of a list of years and corresponding quarters\n",
    "Coffee_x_interval = Coffee_x[:,1]+Coffee_x[:,0]/4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Regression/Correlation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for different methods\n",
    "def LinearReg(x,y):  # Code for regression using the Normal Equation (X.T*X)*theta = (X.T*y)\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x])  # Concatenate x with a column of ones on the left\n",
    "    theta=(np.linalg.solve(np.matmul(X.T,X),np.matmul(X.T,y)))\n",
    "    return theta\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def grad_linear(theta,x,y): # Gradient for linear regression\n",
    "    z= x.dot(theta)\n",
    "    gradient = (1/len(x))*np.matmul(x.T,z-y)\n",
    "    return gradient\n",
    "\n",
    "def grad_linear_stoch (theta,x,y): # Gradient for stochastic linear regression\n",
    "    z=x.dot(theta)\n",
    "    gradient = (1/len(x))*x*(z-y)\n",
    "    return gradient\n",
    "\n",
    "def grad_logistic(theta,x,y): # Gradient for logistic regression\n",
    "    z=x.dot(theta)\n",
    "    gradient = (1/len(x))*np.matmul(x.T,sigmoid(z)-y)\n",
    "    return gradient\n",
    "\n",
    "def GradientDescent(x,y,theta,alpha,iteration,grad): # Code for gradient descent\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x]) # Concatenate x with a column of ones on the left\n",
    "    theta_list = [theta]\n",
    "    for i in range(iteration):\n",
    "        theta = theta - alpha*grad(theta,X,y)\n",
    "        theta_list.append(theta)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    return theta, h, theta_list\n",
    "\n",
    "def StochasticGD(x,y,theta,alpha,iteration,grad): # Code for stochastic gradient descent\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x]) # Concatenate x with a column of ones on the left\n",
    "    theta_list = [theta]\n",
    "    for i in range(iteration):\n",
    "        k=random.randint(1,x.shape[0]-1)\n",
    "        theta = theta - alpha*grad(theta,X[k],y[k])\n",
    "        theta_list.append(theta)\n",
    "    return theta, theta_list\n",
    "\n",
    "def newton_method(x, y, num_iterations):\n",
    "    X = np.hstack([np.ones((x.shape[0],1)),x])  # Concatenate x with a column of ones on the left\n",
    "    m, n = X.shape  \n",
    "    theta = np.zeros(n)  # Initialize the parameters\n",
    "    for _ in range(num_iterations):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        gradient = np.dot(X.T,(h-y))/m  # Calculate the gradient and Hessian\n",
    "        diagonal = np.diag(h*(1-h))\n",
    "        hessian = (1/m)*np.dot(X.T, np.dot(diagonal,X))\n",
    "        theta = theta - np.dot(np.linalg.inv(hessian), gradient) # Update theta using Newton's method\n",
    "    return theta, sigmoid(np.dot(X, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
